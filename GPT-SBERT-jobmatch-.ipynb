{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-15T14:49:23.109044Z",
     "iopub.status.busy": "2024-12-15T14:49:23.108624Z",
     "iopub.status.idle": "2024-12-15T14:49:23.499027Z",
     "shell.execute_reply": "2024-12-15T14:49:23.497867Z",
     "shell.execute_reply.started": "2024-12-15T14:49:23.109009Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/upwork-job-postings-dataset-2024-50k-records/upwork-jobs.csv\n",
      "/kaggle/input/payload-resume/Aninditaa_Resume_ML.pdf\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T14:49:23.500994Z",
     "iopub.status.busy": "2024-12-15T14:49:23.500509Z",
     "iopub.status.idle": "2024-12-15T14:49:35.301039Z",
     "shell.execute_reply": "2024-12-15T14:49:35.299839Z",
     "shell.execute_reply.started": "2024-12-15T14:49:23.500960Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T14:49:35.303195Z",
     "iopub.status.busy": "2024-12-15T14:49:35.302728Z",
     "iopub.status.idle": "2024-12-15T14:49:46.197998Z",
     "shell.execute_reply": "2024-12-15T14:49:46.196841Z",
     "shell.execute_reply.started": "2024-12-15T14:49:35.303141Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.57.4-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (2.10.2)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/conda/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Downloading openai-1.57.4-py3-none-any.whl (390 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.3/390.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.0/345.0 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jiter, openai\n",
      "Successfully installed jiter-0.8.2 openai-1.57.4\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade openai\n",
    "#!pip install openai==0.28\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T14:49:46.202242Z",
     "iopub.status.busy": "2024-12-15T14:49:46.201699Z",
     "iopub.status.idle": "2024-12-15T14:49:46.207723Z",
     "shell.execute_reply": "2024-12-15T14:49:46.206584Z",
     "shell.execute_reply.started": "2024-12-15T14:49:46.202191Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T14:49:46.209367Z",
     "iopub.status.busy": "2024-12-15T14:49:46.209056Z",
     "iopub.status.idle": "2024-12-15T14:49:46.440446Z",
     "shell.execute_reply": "2024-12-15T14:49:46.439492Z",
     "shell.execute_reply.started": "2024-12-15T14:49:46.209338Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T14:49:46.441901Z",
     "iopub.status.busy": "2024-12-15T14:49:46.441561Z",
     "iopub.status.idle": "2024-12-15T14:49:56.981123Z",
     "shell.execute_reply": "2024-12-15T14:49:56.979969Z",
     "shell.execute_reply.started": "2024-12-15T14:49:46.441868Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.46.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.4.0+cpu)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.26.2)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.15.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.20.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.6.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-3.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T14:49:56.984158Z",
     "iopub.status.busy": "2024-12-15T14:49:56.983092Z",
     "iopub.status.idle": "2024-12-15T14:50:19.355480Z",
     "shell.execute_reply": "2024-12-15T14:50:19.354331Z",
     "shell.execute_reply.started": "2024-12-15T14:49:56.984102Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T14:50:19.357728Z",
     "iopub.status.busy": "2024-12-15T14:50:19.356886Z",
     "iopub.status.idle": "2024-12-15T14:50:19.364791Z",
     "shell.execute_reply": "2024-12-15T14:50:19.361966Z",
     "shell.execute_reply.started": "2024-12-15T14:50:19.357690Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T14:50:19.369717Z",
     "iopub.status.busy": "2024-12-15T14:50:19.369016Z",
     "iopub.status.idle": "2024-12-15T14:50:20.060312Z",
     "shell.execute_reply": "2024-12-15T14:50:20.059291Z",
     "shell.execute_reply.started": "2024-12-15T14:50:19.369644Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = '**************************************************'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T14:50:20.064657Z",
     "iopub.status.busy": "2024-12-15T14:50:20.064226Z",
     "iopub.status.idle": "2024-12-15T14:50:20.069943Z",
     "shell.execute_reply": "2024-12-15T14:50:20.068934Z",
     "shell.execute_reply.started": "2024-12-15T14:50:20.064621Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Pandas display settings to prevent truncation\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T14:50:20.071406Z",
     "iopub.status.busy": "2024-12-15T14:50:20.071085Z",
     "iopub.status.idle": "2024-12-15T14:50:22.252283Z",
     "shell.execute_reply": "2024-12-15T14:50:22.251055Z",
     "shell.execute_reply.started": "2024-12-15T14:50:20.071352Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle file not found. Loading from CSV and creating pickle.\n",
      "Pickle file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Dataset Handling - Create a pickle file on first run\n",
    "csv_file_path = \"/kaggle/input/upwork-job-postings-dataset-2024-50k-records/upwork-jobs.csv\"  # Replace with your dataset path\n",
    "pkl_file_path = \"job_df.pkl\"\n",
    "\n",
    "if os.path.exists(pkl_file_path):\n",
    "    # Load from pickle for faster access\n",
    "    job_df = pd.read_pickle(pkl_file_path)\n",
    "    print(\"DataFrame loaded from pickle file.\")\n",
    "else:\n",
    "    # Read from CSV and save as pickle\n",
    "    print(\"Pickle file not found. Loading from CSV and creating pickle.\")\n",
    "    job_df = pd.read_csv(csv_file_path)\n",
    "    job_df.to_pickle(pkl_file_path)\n",
    "    print(\"Pickle file created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T14:50:22.313966Z",
     "iopub.status.busy": "2024-12-15T14:50:22.313562Z",
     "iopub.status.idle": "2024-12-15T14:50:34.858374Z",
     "shell.execute_reply": "2024-12-15T14:50:34.857076Z",
     "shell.execute_reply.started": "2024-12-15T14:50:22.313931Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/conda/lib/python3.10/site-packages (1.57.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (2.10.2)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/conda/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Extracted Information from Resume:\n",
      " 1. Skills:\n",
      "- Languages: Python, Java, Golang, C/C++\n",
      "- Tools: GCP, Vertex AI, Kubernetes, Helm, Docker, git\n",
      "- Frameworks/Technologies: LangChain, Mediapipe, TensorFlow, OpenCV, scikit-learn, Redis, MongoDB\n",
      "\n",
      "2. Education:\n",
      "- Master of Science in Computer Science (Thesis), Virginia Tech, Aug 2024 - Present\n",
      "- Bachelor of Technology in Computer Science and Engineering, Manipal University Jaipur, July 2019 - June 2023\n",
      "\n",
      "3. Work Experience:\n",
      "- Software Engineer, Harness [Software Delivery Platform], Bangalore, India, Aug 2023 - July 2024\n",
      "- Software Engineering Intern, Harness [Software Delivery Platform], Bangalore, India, Feb 2023 - Aug 2023\n",
      "- Research Intern, CVIT Lab - IIIT Hyderabad, Hyd, India, June 2022 – Sept 2022\n",
      "\n",
      "4. Total Years of Experience: Based on the provided information, Aninditaa Chauhan has approximately 2 years of work experience.\n"
     ]
    }
   ],
   "source": [
    "# Extract information from the resume using OpenAI GPT\n",
    "!pip install openai\n",
    "import openai\n",
    "\n",
    "def extract_information_from_resume(resume_text):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an assistant that extracts structured information from resumes.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Extract the following information from the resume below:\\n\\n1. Skills\\n2. Education or Qualifications\\n3. Work Experience (including roles and companies)\\n4. Total Years of Experience\\n\\nResume:\\n{resume_text}\"}\n",
    "        ],\n",
    "        max_tokens=1000,\n",
    "        temperature=0.5\n",
    "    )\n",
    "\n",
    "    #extracted_info = response['choices'][0]['message']['content'].strip()\n",
    "    extracted_info = response.choices[0].message.content\n",
    "    return extracted_info\n",
    "\n",
    "extracted_info = extract_information_from_resume(resume_text)\n",
    "print(\"Extracted Information from Resume:\\n\", extracted_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T14:50:22.254032Z",
     "iopub.status.busy": "2024-12-15T14:50:22.253645Z",
     "iopub.status.idle": "2024-12-15T14:50:22.312430Z",
     "shell.execute_reply": "2024-12-15T14:50:22.311294Z",
     "shell.execute_reply.started": "2024-12-15T14:50:22.253999Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the resume file\n",
    "resume_file_path = \"/kaggle/input/payload-resume/Aninditaa_Resume_ML.pdf\"  # Replace with your file name\n",
    "if os.path.exists(resume_file_path):\n",
    "    def extract_text_from_pdf(file_path):\n",
    "        with open(file_path, 'rb') as file:\n",
    "            reader = PdfReader(file)\n",
    "            text = ''.join([page.extract_text() for page in reader.pages])\n",
    "        return text\n",
    "\n",
    "    resume_text = extract_text_from_pdf(resume_file_path)\n",
    "else:\n",
    "    print(f\"Resume file '{resume_file_path}' not found.\")\n",
    "    resume_text = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T14:50:34.860717Z",
     "iopub.status.busy": "2024-12-15T14:50:34.860228Z",
     "iopub.status.idle": "2024-12-15T14:50:34.871306Z",
     "shell.execute_reply": "2024-12-15T14:50:34.869839Z",
     "shell.execute_reply.started": "2024-12-15T14:50:34.860662Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Parse extracted information\n",
    "def parse_extracted_info(extracted_text):\n",
    "    skills_match = re.search(r'Skills:(.*?)(Education|$)', extracted_text, re.DOTALL | re.IGNORECASE)\n",
    "    education_match = re.search(r'Education:(.*?)(Experience|$)', extracted_text, re.DOTALL | re.IGNORECASE)\n",
    "    experience_match = re.search(r'Experience:(.*?)(Total Years of Experience|$)', extracted_text, re.DOTALL | re.IGNORECASE)\n",
    "    years_match = re.search(r'Total Years of Experience:(.*)', extracted_text, re.DOTALL | re.IGNORECASE)\n",
    "\n",
    "    skills = [skill.strip() for skill in skills_match.group(1).split(',')] if skills_match else []\n",
    "    education = [degree.strip() for degree in education_match.group(1).split(',')] if education_match else []\n",
    "    experience = [exp.strip() for exp in experience_match.group(1).split(',')] if experience_match else []\n",
    "    total_years = years_match.group(1).strip() if years_match else \"0\"\n",
    "\n",
    "    return skills, education, experience, total_years\n",
    "\n",
    "skills, education, experience, total_years = parse_extracted_info(extracted_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T14:50:34.873041Z",
     "iopub.status.busy": "2024-12-15T14:50:34.872630Z",
     "iopub.status.idle": "2024-12-15T14:50:37.707505Z",
     "shell.execute_reply": "2024-12-15T14:50:37.706323Z",
     "shell.execute_reply.started": "2024-12-15T14:50:34.873005Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d47ae872d3544c9a8badbd205f067e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48719694b9d646e98201e6d3e65bc821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5bc44b9df4444ce94329a8bf0f748bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c2eb830d014629bc3d6d82dda307d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885ee1e4b9e74be998c5c31b3a13ff04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6add7251f248beb521ac711462a9ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b366f15a833848488d81ae5f062cbc42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6dd7d1d86145bfbb89c2895b22576e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b2a6970322444a8ba0abf4895c576f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6935ffa60c34a909500d8a2f3b7fe6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "456a6743c55740ddbe73e9264552bd5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the Sentence Transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T14:50:37.709171Z",
     "iopub.status.busy": "2024-12-15T14:50:37.708836Z",
     "iopub.status.idle": "2024-12-15T14:50:37.713960Z",
     "shell.execute_reply": "2024-12-15T14:50:37.712806Z",
     "shell.execute_reply.started": "2024-12-15T14:50:37.709140Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Function to calculate match score using BERT embeddings and cosine similarity\n",
    "# def calculate_match_score_bert(job_description, resume_text):\n",
    "#     job_embedding = model.encode(job_description, convert_to_tensor=True)\n",
    "#     resume_embedding = model.encode(resume_text, convert_to_tensor=True)\n",
    "#     similarity_score = util.pytorch_cos_sim(job_embedding, resume_embedding).item()\n",
    "#     return similarity_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T14:50:37.715872Z",
     "iopub.status.busy": "2024-12-15T14:50:37.715438Z",
     "iopub.status.idle": "2024-12-15T15:40:54.524575Z",
     "shell.execute_reply": "2024-12-15T15:40:54.523235Z",
     "shell.execute_reply.started": "2024-12-15T14:50:37.715835Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f230f16db3a442068994b30d394fd584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating job embeddings in batch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "644acef71d6b471a8c6e419732a2ff67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1659 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating cosine similarity...\n"
     ]
    }
   ],
   "source": [
    "# Inefficient for large datasets\n",
    "# if 'description' in job_df.columns:\n",
    "#     job_df['Match Score'] = job_df['description'].apply(lambda x: calculate_match_score_bert(x, resume_text))\n",
    "\n",
    "# Optimized batch processing for BERT embeddings\n",
    "job_descriptions = job_df['description'].tolist()\n",
    "resume_embedding = model.encode(resume_text, convert_to_tensor=True)\n",
    "\n",
    "print(\"Generating job embeddings in batch...\")\n",
    "job_embeddings = model.encode(job_descriptions, convert_to_tensor=True)\n",
    "\n",
    "# Calculate cosine similarity for all job descriptions at once\n",
    "print(\"Calculating cosine similarity...\")\n",
    "similarity_scores = util.pytorch_cos_sim(job_embeddings, resume_embedding).squeeze()\n",
    "\n",
    "# Assign similarity scores to 'Match Score'\n",
    "job_df['Match Score'] = similarity_scores.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T15:40:54.526310Z",
     "iopub.status.busy": "2024-12-15T15:40:54.525986Z",
     "iopub.status.idle": "2024-12-15T15:40:54.574188Z",
     "shell.execute_reply": "2024-12-15T15:40:54.573157Z",
     "shell.execute_reply.started": "2024-12-15T15:40:54.526278Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Matching Job Postings:\n",
      "                                                                                  title  \\\n",
      "19986       Deep Learning based System for\\nECG Classification Using Fourier Transform   \n",
      "51876            MMDetection Framework Specialist for Custom Faster-RCNN Loss Function   \n",
      "24274      Machine Learning Expert Needed for Morphological Classification of Galaxies   \n",
      "9429                                     Medical Imaging AI and automatic segmentation   \n",
      "24049                                                            Deep learning project   \n",
      "4295                                                           AI medical data project   \n",
      "51399                            AI Specialist for Health Prediction Model Development   \n",
      "27562  Deep Learning Model for Real-Time Object Detection and Current State Prediction   \n",
      "7955                                         Dynamic K-Selection for Similarity Models   \n",
      "13006                                                            Senior Data Scientist   \n",
      "\n",
      "                                                                                                                                               link  \\\n",
      "19986        https://www.upwork.com/jobs/Deep-Learning-based-System-for-ECG-Classification-Using-Fourier-Transform_%7E01768fbf3388f733b6?source=rss   \n",
      "51876            https://www.upwork.com/jobs/MMDetection-Framework-Specialist-for-Custom-Faster-RCNN-Loss-Function_%7E017fc1e8b3e6f59fae?source=rss   \n",
      "24274         https://www.upwork.com/jobs/Machine-Learning-Expert-Needed-for-Morphological-Classification-Galaxies_%7E01aa4f57fe92d02e2c?source=rss   \n",
      "9429                                        https://www.upwork.com/jobs/Medical-Imaging-and-automatic-segmentation_%7E01f018f69ca64066c9?source=rss   \n",
      "24049                                                            https://www.upwork.com/jobs/Deep-learning-project_%7E01e2faebdbbc9c1dbd?source=rss   \n",
      "4295                                                              https://www.upwork.com/jobs/medical-data-project_%7E016c659e7affd18f42?source=rss   \n",
      "51399                               https://www.upwork.com/jobs/Specialist-for-Health-Prediction-Model-Development_%7E01873849a555844c1d?source=rss   \n",
      "27562  https://www.upwork.com/jobs/Deep-Learning-Model-for-Real-Time-Object-Detection-and-Current-State-Prediction_%7E0161c52bc920dc23d2?source=rss   \n",
      "7955                                           https://www.upwork.com/jobs/Dynamic-Selection-for-Similarity-Models_%7E01d8ed5461e05066bc?source=rss   \n",
      "13006                                                            https://www.upwork.com/jobs/Senior-Data-Scientist_%7E019ff4837ecb6531c3?source=rss   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        description  \\\n",
      "19986                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              —The threat of heart disease has increasedthroughout history due to the difficulty of diagnosing it andthe need for experienced doctors. Heart disease can be causedby various of factors such as age, high blood pressure, anddiabetes. This paper investigates the arrythmia ofElectrocardiogram (ECG) by comparing and evaluatingdifferent classifiers to predict the abnormalities of aheartbeat. We have developed a system that predictsheartbeat arrhythmia using a multi-classifier deep learningmodel. By using MIT-BIH Arrythmia Database, we were ableto achieve an accuracy of 97.4%. Compared to other modelsthat we have implemented; this model recorded the highestperformance.Pls check the attached paper.Budget: $200Posted On: February 13, 2024 19:38 UTCCategory: Deep LearningSkills:Deep Learning,     Machine LearningSkills:        Deep Learning,                     Machine LearningCountry: Pakistanclick to apply   \n",
      "51876                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Job Description:We are looking for an experienced Deep Learning Engineer with a strong background in object detection frameworks, particularly MMDetection, to implement a custom modification to the Faster-RCNN model. The goal is to compute the loss as the average between the loss on an original input image and its augmented counterpart without using gradients for the augmented image.Core Responsibilities:Set up the MMDetection framework with the Faster-RCNN model using a simple baseline dataset, such as the balloon dataset. (Use mmdetection  3.2 or above).Implement a preprocessing step that precomputes one augmented image for each original image in the dataset.Modify the data loading process to handle pairs of original and augmented images simultaneously, ensuring that the data preprocessing (e.g., normalization, resizing) is consistent between pairs.Customize the loss function of Faster-RCNN to calculate the average loss of the image pairs, explicitly avoiding the computation of gradients for the augmented images to act as a regularization term.Provide insights and documentation on the implementation process and any modifications to the MMDetection framework.Provide a final delivarable that shows the code in action such that it can be reprocuded in our own project.Key Requirements:Proficiency in PyTorch and MMDetection with a solid understanding of Faster-RCNN.Experience with image augmentation techniques and multiprocessing for efficient computation.Ability to write clean, maintainable, and well-documented code.Budget: $150Posted On: February 23, 2024 11:24 UTCCategory: Deep LearningSkills:Python,     Computer Vision,     Machine Learning,     Artificial Intelligence,     Deep LearningSkills:        Python,                     Computer Vision,                     Machine Learning,                     Artificial Intelligence,                     Deep LearningCountry: Germanyclick to apply   \n",
      "24274                                                                                                                                                                                                                                                                                                          We are seeking a skilled machine learning expert to take on the exciting challenge of morphological classification of galaxies. This project involves developing a robust image classification model to distinguish different morphological types of galaxies based on provided datasets.Key Responsibilities:1.\\tData Preprocessing: Clean and preprocess the galaxy image datasets to ensure high-quality input for machine learning models.2.\\tFeature Extraction: Identify relevant features that characterize the morphological properties of galaxies and extract them from the image data.3.\\tModel Development: Design and implement a machine learning model capable of accurately classifying galaxies into distinct morphological categories.4.\\tHyperparameter Tuning: Fine-tune model hyperparameters to optimize performance and ensure robust generalization on unseen data.5.\\tValidation and Testing: Rigorously validate the model's performance using appropriate evaluation metrics and conduct thorough testing to ensure reliability.6.\\tDocumentation: Provide clear documentation of the developed model, including the methodology, codebase, and instructions for future use or modifications.Requirements:•\\tProven experience in machine learning, particularly in image classification tasks.•\\tFamiliarity with astrophysics or astronomy concepts is a plus.•\\tProficiency in relevant programming languages such as Python, and experience with popular machine learning frameworks (e.g., TensorFlow, PyTorch).•\\tStrong analytical and problem-solving skills.To apply, please submit a proposal detailing your relevant experience, approach to solving the problem, estimated timeline, and any relevant portfolio or previous projects. The selected candidate will have the opportunity to contribute to groundbreaking research in the field of astrophysics while advancing their machine learning expertise.If you're passionate about pushing the boundaries of machine learning in the realm of astrophysics, we invite you to join our team and contribute to the understanding of galaxy morphologies.Budget: $10Posted On: February 19, 2024 09:57 UTCCategory: Machine LearningSkills:Machine Learning,     Python,     Data Science,     TensorFlow,     Deep Learning,     Artificial Intelligence,     Artificial Neural Network,     Natural Language ProcessingSkills:        Machine Learning,                     Python,                     Data Science,                     TensorFlow,                     Deep Learning,                     Artificial Intelligence,                     Artificial Neural Network,                     Natural Language ProcessingCountry: United Statesclick to apply   \n",
      "9429                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Using MedLSam to segment vessels from CT angiography images. Setting up data flow pipeline from desktop app to cloud based machine learning service.Budget: $2,000Posted On: February 14, 2024 01:12 UTCCategory: Deep LearningSkills:Artificial Intelligence,     Python,     Machine Learning,     Computer Vision,     Neural Network,     Deep Learning,     TensorFlow,     Artificial Neural Network,     KerasSkills:        Artificial Intelligence,                     Python,                     Machine Learning,                     Computer Vision,                     Neural Network,                     Deep Learning,                     TensorFlow,                     Artificial Neural Network,                     KerasLocation Requirement: Only freelancers located in the United States may apply.Country: United Statesclick to apply   \n",
      "24049                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       In this project you  will be designing a deep convolutional neural network to classify an image of a cooking object to one of its states. For example given an image of a “sliced tomato” or “sliced bread”, the network should give as output “sliced”.You will be only working on part -2 and part -3Attached pdf ..which has everything22nd deadlineBudget: $10Posted On: February 20, 2024 20:16 UTCCategory: Deep LearningSkills:Deep Learning,     Keras,     Neural Network,     Deep Neural Network,     Machine Learning,     PythonSkills:        Deep Learning,                     Keras,                     Neural Network,                     Deep Neural Network,                     Machine Learning,                     PythonCountry: United Statesclick to apply   \n",
      "4295                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      I need expert that can help me to build AI model to classifying medical data.Budget: $475Posted On: February 23, 2024 14:20 UTCCategory: Deep LearningSkills:Artificial Intelligence,     Machine LearningSkills:        Artificial Intelligence,                     Machine LearningCountry: Saudi Arabiaclick to apply   \n",
      "51399                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                We are seeking a talented and experienced AI Specialist to join our team on a project basis. The primary focus of this project is to develop machine learning models for predicting health outcomes in users based on blood sugar levels. The successful candidate will be responsible for the end-to-end development of these models, from research to deployment.Responsibilities:Conduct research on health prediction using blood sugar data and related factors.Develop machine learning models for predicting health outcomes, with a focus on accuracy and performance.Implement and evaluate algorithms using a variety of machine learning and statistical modeling techniques.Utilize data cleansing techniques to preprocess and prepare large datasets for training.Collaborate with cross-functional teams to ensure seamless integration and deployment of the developed models.Monitor and optimize model performance over time to maintain accuracy and quality.Requirements:Proven experience in developing machine learning models for health prediction or related fields.Strong background in machine learning, statistical modeling, and data analysis techniques.Proficiency in programming languages such as Python, R, or MATLAB.Experience with data cleansing techniques and handling large datasets.Familiarity with machine learning frameworks and libraries such as TensorFlow, PyTorch, scikit-learn, etc.Excellent problem-solving skills and ability to work independently.Good communication skills and ability to collaborate with cross-functional teams.Previous experience in healthcare or medical data analysis is a plus.Hourly Range: $25.00-$45.00Posted On: February 22, 2024 10:18 UTCCategory: Machine LearningSkills:OpenCV,     Machine Learning,     Python,     Artificial Intelligence,     Data Science,     TensorFlow,     Neural Network,     Natural Language Processing,     Deep Learning,     Artificial Neural NetworkSkills:        OpenCV,                     Machine Learning,                     Python,                     Artificial Intelligence,                     Data Science,                     TensorFlow,                     Neural Network,                     Natural Language Processing,                     Deep Learning,                     Artificial Neural NetworkCountry: Pakistanclick to apply   \n",
      "27562  Description:We are seeking an experienced deep learning engineer to develop a robust system for classifying real Watches and predicting their current state using bulk data(4k-9k). The project involves building a model that can accurately identify whether an input image contains a genuine watch and classify its current condition.Key Responsibilities:Collect and preprocess a large dataset of Products(4000) of real watches covering various models, angles, lighting conditions, and backgrounds.Develop and train a deep learning model, preferably using convolutional neural networks (CNNs), to classify watches and predict their current state.Implement the model in a web-based application where users can capture and display images of watches through a webcam interface.Ensure the system provides accurate predictions in real-time and displays the classification results to the user.Required Skills:Strong background in deep learning, computer vision, and image classification.Proficiency in Python programming and popular deep learning frameworks such as Tensor Flow or PyTorch.Experience with data preprocessing techniques, model training, and evaluation.Familiarity with web development frameworks for building interactive applications.Additional Requirements:Ability to optimize the model for real-time performance and deploy it in a web-based environment.Problem Statement:Currently, we are facing challenges in accurately predicting the labels of bulk watches captured through the webcam interface. Despite using a large dataset which are the same familier or different shape of the object(Example : Square, Round , oval , Rectangle , others ) and a well-trained deep learning model, the system sometimes misclassifies the watches or fails to detect certain features accurately. We need a solution that can improve the accuracy and robustness of the model, especially in real-time scenarios where lighting conditions and camera angles may vary.If you have the skills and expertise to tackle this problem and build a reliable system for classifying real Titan watches and predicting their current state, we'd love to hear from you.This project offers an exciting opportunity to contribute to the development of an innovative application with real-world impact. We look forward to collaborating with a talented and dedicated professional who shares our passion for leveraging technology to solve complex challenges.Posted On: February 22, 2024 11:30 UTCCategory: Deep LearningSkills:TensorFlow,     Machine Learning,     Computer Vision,     Neural Network,     Deep Learning,     Convolutional Neural Network,     Data Science,     PyTorchSkills:        TensorFlow,                     Machine Learning,                     Computer Vision,                     Neural Network,                     Deep Learning,                     Convolutional Neural Network,                     Data Science,                     PyTorchCountry: Indiaclick to apply   \n",
      "7955                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               We are seeking a skilled Deep Learning Engineer to develop and implement a state-of-the-art deep learning model designed to identify similarities within our dataset, utilizing a dynamically chosen K-value sourced from a vector-based database. This project aims to enhance our system's ability to make intelligent matches and recommendations by accurately identifying patterns and similarities across a vast dataset. The successful candidate will integrate this model into our existing infrastructure, ensuring scalability, efficiency, and accuracy.Budget: $20Posted On: February 14, 2024 12:21 UTCCategory: Machine LearningSkills:Python,     Deep Learning,     Artificial IntelligenceSkills:        Python,                     Deep Learning,                     Artificial IntelligenceCountry: Pakistanclick to apply   \n",
      "13006                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           The ideal candidate should have a strong academic background, including a PhD in Machine Learning or AI, and extensive experience in building and optimizing Bayesian Networks and ML algorithms for healthcare applications, such as disease diagnosis, treatment prediction, or personalized medicine.We are looking for someone passionate about data science and eager to work with cutting-edge technologies. You will have the opportunity to collaborate with a team of talented professionals and contribute to groundbreaking solutions that can make a difference in the healthcare industry.You must have hands-on experience with Java or similar technologies.We need somebody who will drive our initiative that has the objective of leveraging machine learning techniques to improve the quality of our AI healthcare product.If you meet these qualifications and are interested in this opportunity, we encourage you to apply and become part of our team. Join us in our pursuit of excellence and innovation in the field of data science for healthcare.We are open to applications from candidates based in the USA, LatAm, UK, or Europe.Hourly Range: $35.00-$70.00Posted On: February 14, 2024 11:54 UTCCategory: Machine LearningSkills:Bayesian Statistics,     Java,     Python,     Data Science,     Machine LearningSkills:        Bayesian Statistics,                     Java,                     Python,                     Data Science,                     Machine LearningCountry: Ukraineclick to apply   \n",
      "\n",
      "                  published_date is_hourly  hourly_low  hourly_high  budget  \\\n",
      "19986  2024-02-13 19:38:08+00:00     False         NaN          NaN   200.0   \n",
      "51876  2024-02-23 11:24:17+00:00     False         NaN          NaN   150.0   \n",
      "24274  2024-02-19 09:57:20+00:00     False         NaN          NaN    10.0   \n",
      "9429   2024-02-14 01:12:06+00:00     False         NaN          NaN  2000.0   \n",
      "24049  2024-02-20 20:16:42+00:00     False         NaN          NaN    10.0   \n",
      "4295   2024-02-23 14:20:27+00:00     False         NaN          NaN   475.0   \n",
      "51399  2024-02-22 10:18:47+00:00      True        25.0         45.0     NaN   \n",
      "27562  2024-02-22 11:30:53+00:00       NaN         NaN          NaN     NaN   \n",
      "7955   2024-02-14 12:21:37+00:00     False         NaN          NaN    20.0   \n",
      "13006  2024-02-14 11:54:02+00:00      True        35.0         70.0     NaN   \n",
      "\n",
      "             country  Match Score  \n",
      "19986       Pakistan     0.524257  \n",
      "51876        Germany     0.470198  \n",
      "24274  United States     0.446851  \n",
      "9429   United States     0.431710  \n",
      "24049  United States     0.400562  \n",
      "4295    Saudi Arabia     0.400119  \n",
      "51399       Pakistan     0.399426  \n",
      "27562          India     0.388139  \n",
      "7955        Pakistan     0.386852  \n",
      "13006        Ukraine     0.382742  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Filtering and displaying top matching jobs (configurable number of top matches)\n",
    "top_n = 10  # Adjust as needed\n",
    "matching_jobs = job_df.sort_values(by='Match Score', ascending=False).head(top_n)\n",
    "print(\"Top Matching Job Postings:\\n\", matching_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T15:50:55.897961Z",
     "iopub.status.busy": "2024-12-15T15:50:55.897538Z",
     "iopub.status.idle": "2024-12-15T15:50:55.907319Z",
     "shell.execute_reply": "2024-12-15T15:50:55.906165Z",
     "shell.execute_reply.started": "2024-12-15T15:50:55.897924Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 matching Jobs:\n",
      "                                                                                 title  \\\n",
      "19986       Deep Learning based System for\\nECG Classification Using Fourier Transform   \n",
      "51876            MMDetection Framework Specialist for Custom Faster-RCNN Loss Function   \n",
      "24274      Machine Learning Expert Needed for Morphological Classification of Galaxies   \n",
      "9429                                     Medical Imaging AI and automatic segmentation   \n",
      "24049                                                            Deep learning project   \n",
      "4295                                                           AI medical data project   \n",
      "51399                            AI Specialist for Health Prediction Model Development   \n",
      "27562  Deep Learning Model for Real-Time Object Detection and Current State Prediction   \n",
      "7955                                         Dynamic K-Selection for Similarity Models   \n",
      "13006                                                            Senior Data Scientist   \n",
      "\n",
      "                  published_date        country  Match Score  \n",
      "19986  2024-02-13 19:38:08+00:00       Pakistan     0.524257  \n",
      "51876  2024-02-23 11:24:17+00:00        Germany     0.470198  \n",
      "24274  2024-02-19 09:57:20+00:00  United States     0.446851  \n",
      "9429   2024-02-14 01:12:06+00:00  United States     0.431710  \n",
      "24049  2024-02-20 20:16:42+00:00  United States     0.400562  \n",
      "4295   2024-02-23 14:20:27+00:00   Saudi Arabia     0.400119  \n",
      "51399  2024-02-22 10:18:47+00:00       Pakistan     0.399426  \n",
      "27562  2024-02-22 11:30:53+00:00          India     0.388139  \n",
      "7955   2024-02-14 12:21:37+00:00       Pakistan     0.386852  \n",
      "13006  2024-02-14 11:54:02+00:00        Ukraine     0.382742  \n"
     ]
    }
   ],
   "source": [
    "  print(\"\\nTop 10 matching Jobs:\")\n",
    "  print(matching_jobs[['title', 'published_date', 'country', 'Match Score']].head(10))\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4488372,
     "sourceId": 7690995,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6306370,
     "sourceId": 10204889,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6306507,
     "sourceId": 10205095,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
