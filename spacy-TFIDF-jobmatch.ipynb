{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7690995,"sourceType":"datasetVersion","datasetId":4488372},{"sourceId":10207098,"sourceType":"datasetVersion","datasetId":6308032}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-15T15:34:41.512047Z","iopub.execute_input":"2024-12-15T15:34:41.512460Z","iopub.status.idle":"2024-12-15T15:34:41.519786Z","shell.execute_reply.started":"2024-12-15T15:34:41.512431Z","shell.execute_reply":"2024-12-15T15:34:41.518892Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/upwork-job-postings-dataset-2024-50k-records/upwork-jobs.csv\n/kaggle/input/payload-resume2/Aninditaa_Resume_ML.pdf\n","output_type":"stream"}],"execution_count":95},{"cell_type":"code","source":"!pip install PyPDF2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T15:34:41.580200Z","iopub.execute_input":"2024-12-15T15:34:41.580901Z","iopub.status.idle":"2024-12-15T15:34:49.747489Z","shell.execute_reply.started":"2024-12-15T15:34:41.580864Z","shell.execute_reply":"2024-12-15T15:34:49.746366Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: PyPDF2 in /opt/conda/lib/python3.10/site-packages (3.0.1)\n","output_type":"stream"}],"execution_count":96},{"cell_type":"code","source":"# -*- coding: utf-8 -*-\n# Modified for Kaggle: Batch Job Recommendations & Total Experience Calculation\n\n# Install necessary packages\nimport pandas as pd\nimport numpy as np\nimport re\nimport spacy\nimport os\nfrom datetime import datetime\nfrom PyPDF2 import PdfReader\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Load SpaCy model\nnlp = spacy.load(\"en_core_web_sm\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T15:34:49.749637Z","iopub.execute_input":"2024-12-15T15:34:49.749929Z","iopub.status.idle":"2024-12-15T15:34:50.360412Z","shell.execute_reply.started":"2024-12-15T15:34:49.749903Z","shell.execute_reply":"2024-12-15T15:34:50.359467Z"}},"outputs":[],"execution_count":97},{"cell_type":"code","source":"# Check if the pickle file exists\nif os.path.exists(\"job_df.pkl\"):\n    job_df = pd.read_pickle(\"job_df.pkl\")\n    print(\"DataFrame loaded from pickle file.\")\nelse:\n    # Load the dataset from Kaggle's \"Input\" section\n  #  csv_file_path = \"/kaggle/input/upwork-job-postings-dataset-2024-50k-records/upwork-jobs.csv\"  # Replace with your dataset path\n    job_df = pd.read_csv(\"/kaggle/input/upwork-job-postings-dataset-2024-50k-records/upwork-jobs.csv\")  # Replace with your dataset path\n    job_df.to_pickle(\"job_df.pkl\")\n    print(\"DataFrame saved successfully as job_df.pkl.\")\n\n \n# Step 1: Load the Resume\n\ndef load_resume(file_path):\n    if file_path.endswith('.pdf'):\n        with open(file_path, 'rb') as file:\n            reader = PdfReader(file)\n            text = \"\".join([page.extract_text() for page in reader.pages ])\n    elif file_path.endswith('.docx'):\n        import docx2txt\n        text = docx2txt.process(file_path)\n    else:\n        raise ValueError(\"Unsupported file format. Use PDF or DOCX.\")\n    return text\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T15:34:50.362077Z","iopub.execute_input":"2024-12-15T15:34:50.362461Z","iopub.status.idle":"2024-12-15T15:34:50.531984Z","shell.execute_reply.started":"2024-12-15T15:34:50.362422Z","shell.execute_reply":"2024-12-15T15:34:50.531088Z"}},"outputs":[{"name":"stdout","text":"DataFrame loaded from pickle file.\n","output_type":"stream"}],"execution_count":98},{"cell_type":"code","source":"# # Step 2: Extract Information and Fix Total Experience\n# def extract_resume_info(resume_text):\n#     skills = {\n#         'Languages': [],\n#         'Tools': [],\n#         'Frameworks/Technologies': []\n#     }\n#     education = []\n#     experience = []\n#     total_experience_months = 0\n\n#     # Extract Skills Section\n#     skills_pattern = re.search(r\"SKILLS:([\\s\\S]*?)(?=(EDUCATION|PROJECTS|EXPERIENCE|$))\", resume_text, re.IGNORECASE)\n#     if skills_pattern:\n#         skills_text = skills_pattern.group(1).split('\\n')\n#         for line in skills_text:\n#             if 'Languages:' in line:\n#                 skills['Languages'] = [item.strip() for item in line.split(':')[1].split(',')]\n#             elif 'Tools:' in line:\n#                 skills['Tools'] = [item.strip() for item in line.split(':')[1].split(',')]\n#             elif 'Frameworks/Technologies:' in line:\n#                 skills['Frameworks/Technologies'] = [item.strip() for item in line.split(':')[1].split(',')]\n\n#     # Extract Education Section\n#     edu_pattern = re.findall(r\"(Master|Bachelor).*?in ([^,]+) from ([^,]+), (\\w+ \\d{4}) - (\\w+ \\d{4}|Present)\", resume_text, re.IGNORECASE)\n#     for degree, field, institution, start, end in edu_pattern:\n#         education.append(f\"{degree} of {field}, {institution}, {start} - {end}\")\n\n#     # Extract Work Experience Section\n#     exp_pattern = re.findall(r\"(.*?) at (.*?), (.*?)\\s*-\\s*(\\w+ \\d{4}|Present)\", resume_text, re.IGNORECASE)\n#     for role, company, location, dates in exp_pattern:\n#         experience.append(f\"{role}, {company}, {location}, {dates}\")\n#         date_matches = re.findall(r\"(\\w+ \\d{4})\", dates)\n#         if len(date_matches) == 2:\n#             try:\n#                 start_date = datetime.strptime(date_matches[0], \"%b %Y\")\n#                 end_date = datetime.strptime(date_matches[1], \"%b %Y\") if date_matches[1] != 'Present' else datetime.now()\n#                 months = (end_date.year - start_date.year) * 12 + (end_date.month - start_date.month)\n#                 total_experience_months += max(months, 0)\n#             except ValueError:\n#                 print(f\"DEBUG: Error parsing dates {dates}\")\n\n#     # Convert months to years\n#     total_experience_years = round(total_experience_months / 12, 1)\n\n#     return {\n#         'skills': skills,\n#         'education': education,\n#         'experience': experience,\n#         'total_experience_years': total_experience_years\n#     }\n\n# Extract information from the resume using OpenAI GPT\n!pip install openai\nimport openai\n\nopenai.api_key = 'sk-svcacct-CHBAA1llvXYtby7INMBGJbqPQ5SSWvqiHHqnAOAWqNmUmmS6oVJ_eX0Ixab8wXFmKwT3BlbkFJupGRsdBRq-ZkCUdnD42l9bO_n3lHhLi-QvFKSPHAAUge4RQt7GBVUKcx4uXh8tKzIA'\n\n\ndef extract_information_from_resume(resume_text):\n    response = openai.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are an assistant that extracts structured information from resumes.\"},\n            {\"role\": \"user\", \"content\": f\"Extract the following information from the resume below:\\n\\n1. Skills\\n2. Education or Qualifications\\n3. Work Experience (including roles and companies)\\n4. Total Years of Experience\\n\\nResume:\\n{resume_text}\"}\n        ],\n        max_tokens=1000,\n        temperature=0.5\n    )\n\n    #extracted_info = response['choices'][0]['message']['content'].strip()\n    extracted_info = response.choices[0].message.content\n    return extracted_info\n\nextracted_info = extract_information_from_resume(resume_text)\nprint(\"Extracted Information from Resume:\\n\", extracted_info)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T15:34:50.534113Z","iopub.execute_input":"2024-12-15T15:34:50.534398Z","iopub.status.idle":"2024-12-15T15:35:01.360244Z","shell.execute_reply.started":"2024-12-15T15:34:50.534373Z","shell.execute_reply":"2024-12-15T15:35:01.359333Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: openai in /opt/conda/lib/python3.10/site-packages (1.57.4)\nRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.4.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.27.0)\nRequirement already satisfied: jiter<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.8.2)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (2.10.1)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.1)\nRequirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.4)\nRequirement already satisfied: typing-extensions<5,>=4.11 in /opt/conda/lib/python3.10/site-packages (from openai) (4.12.2)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\nExtracted Information from Resume:\n 1. Skills:\n- Languages: Python, Java, Golang, C/C++\n- Tools: GCP, Vertex AI, Kubernetes, Helm, Docker, git\n- Frameworks/Technologies: LangChain, Mediapipe, TensorFlow, OpenCV, scikit-learn, Redis, MongoDB\n\n2. Education:\n- Master of Science in Computer Science (Thesis) from Virginia Tech, Aug 2024 - Present\n- Bachelor of Technology in Computer Science and Engineering from Manipal University Jaipur, July 2019 - June 2023\n\n3. Work Experience:\n- Software Engineer at Harness [Software Delivery Platform], Bangalore, India\n  - Aug 2023 - July 2024\n  - Software Engineering Intern\n    - Feb 2023 - Aug 2023\n- Research Intern at CVIT Lab - IIIT Hyderabad, Hyd, India\n  - June 2022 – Sept 2022\n\n4. Total Years of Experience: \n- Based on the provided information, Aninditaa Chauhan has approximately 2 years of work experience.\n","output_type":"stream"}],"execution_count":99},{"cell_type":"code","source":"# Step 3: Display Extracted Information\n# def display_extracted_info(info):\n#     print(\"\\nExtracted Information from Resume:\")\n#     print(\"\\n1. Skills:\")\n#     for skill in info['skills']:\n#         print(f\"- {skill}\")\n#     print(\"\\n2. Education:\")\n#     for edu in info['education']:\n#         print(f\"- {edu}\")\n#     print(\"\\n3. Work Experience:\")\n#     for exp in info['experience']:\n#         print(f\"- {exp}\")\n#     print(f\"\\n4. Total Years of Experience: {info['total_experience_years']} years\")\n\n# Parse extracted information\ndef parse_extracted_info(extracted_text):\n    skills_match = re.search(r'Skills:(.*?)(Education|$)', extracted_text, re.DOTALL | re.IGNORECASE)\n    education_match = re.search(r'Education:(.*?)(Experience|$)', extracted_text, re.DOTALL | re.IGNORECASE)\n    experience_match = re.search(r'Experience:(.*?)(Total Years of Experience|$)', extracted_text, re.DOTALL | re.IGNORECASE)\n    years_match = re.search(r'Total Years of Experience:(.*)', extracted_text, re.DOTALL | re.IGNORECASE)\n\n    skills = [skill.strip() for skill in skills_match.group(1).split(',')] if skills_match else []\n    education = [degree.strip() for degree in education_match.group(1).split(',')] if education_match else []\n    experience = [exp.strip() for exp in experience_match.group(1).split(',')] if experience_match else []\n    total_years = years_match.group(1).strip() if years_match else \"0\"\n\n    return skills, education, experience, total_years\n\nskills, education, experience, total_years = parse_extracted_info(extracted_info)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T15:35:01.361596Z","iopub.execute_input":"2024-12-15T15:35:01.361879Z","iopub.status.idle":"2024-12-15T15:35:01.369582Z","shell.execute_reply.started":"2024-12-15T15:35:01.361850Z","shell.execute_reply":"2024-12-15T15:35:01.368757Z"}},"outputs":[],"execution_count":100},{"cell_type":"code","source":"# Step 4: Vectorization and Similarity Calculation (Batch PRocessing)\n\n# def calculate_similarity(resume_text, job_descriptions):\n#     vectorizer = TfidfVectorizer(stop_words='english', max_features=10000)\n#     combined_texts = [resume_text] + job_descriptions\n#     tfidf_matrix = vectorizer.fit_transform(combined_texts)\n#     similarity_matrix = cosine_similarity(tfidf_matrix)\n#     return similarity_matrix[0, 1:]\n\n\ndef calculate_similarity_in_batches(resume_text, job_descriptions, batch_size=5000):\n    vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n    similarities = []\n\n    for i in range(0, len(job_descriptions), batch_size):\n        batch = job_descriptions[i:i + batch_size]\n        combined_texts = [resume_text] + batch\n        tfidf_matrix = vectorizer.fit_transform(combined_texts)\n        batch_similarities = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:]).flatten()\n        similarities.extend(batch_similarities)\n\n    return similarities","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T15:35:01.370581Z","iopub.execute_input":"2024-12-15T15:35:01.370794Z","iopub.status.idle":"2024-12-15T15:35:01.381698Z","shell.execute_reply.started":"2024-12-15T15:35:01.370772Z","shell.execute_reply":"2024-12-15T15:35:01.380970Z"}},"outputs":[],"execution_count":101},{"cell_type":"code","source":"# Step 5: Match and Rank Jobs\n\n# def match_jobs(resume_text, job_db):\n#     job_db_subset = job_db.copy()\n#     similarities = calculate_similarity(resume_text, job_db_subset['description'].tolist())\n#     job_db_subset['similarity_score'] = similarities  # No normalization\n#     sorted_jobs = job_db_subset.sort_values(by='similarity_score', ascending=False)\n#     return sorted_jobs\n\ndef match_jobs(resume_text, job_db_path, chunksize=5000):\n    top_matches = []\n    for chunk in pd.read_csv(job_db_path, chunksize=chunksize):\n        similarities = calculate_similarity_in_batches(resume_text, chunk['description'].tolist())\n        chunk['similarity_score'] = similarities\n        top_matches.append(chunk.sort_values(by='similarity_score', ascending=False).head(10))\n    return pd.concat(top_matches).sort_values(by='similarity_score', ascending=False).head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T15:35:01.382685Z","iopub.execute_input":"2024-12-15T15:35:01.382936Z","iopub.status.idle":"2024-12-15T15:35:01.396734Z","shell.execute_reply.started":"2024-12-15T15:35:01.382895Z","shell.execute_reply":"2024-12-15T15:35:01.395982Z"}},"outputs":[],"execution_count":102},{"cell_type":"code","source":"\n# Main Execution\nif __name__ == \"__main__\":\n    # Load the resume\n    resume_file_path = \"/kaggle/input/payload-resume2/Aninditaa_Resume_ML.pdf\"  # Replace with your Kaggle path\n    if os.path.exists(resume_file_path):\n        resume_text = load_resume(resume_file_path)\n\n        # Extract information from resume\n        resume_info = extract_information_from_resume(resume_text)\n        # display_extracted_info(resume_info)\n        print(extracted_info)\n\n        # Load job dataset\n        job_dataset_path = \"/kaggle/input/upwork-job-postings-dataset-2024-50k-records/upwork-jobs.csv\"  # Replace with your dataset path\n        if os.path.exists(job_dataset_path):\n            job_df = pd.read_csv(job_dataset_path)\n\n            # Match jobs and get recommendations\n            recommended_jobs = match_jobs(resume_text, job_dataset_path)\n\n            print(\"\\nTop 10 Recommended Jobs:\")\n            print(recommended_jobs[['title', 'description', 'published_date', 'country', 'similarity_score']].head(10))\n        else:\n            print(f\"Error: Job dataset file '{job_dataset_path}' not found.\")\n    else:\n        print(f\"Error: Resume file '{resume_file_path}' not found.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T15:38:03.758160Z","iopub.execute_input":"2024-12-15T15:38:03.758954Z","iopub.status.idle":"2024-12-15T15:38:14.097000Z","shell.execute_reply.started":"2024-12-15T15:38:03.758922Z","shell.execute_reply":"2024-12-15T15:38:14.096052Z"}},"outputs":[{"name":"stdout","text":"1. Skills:\n- Languages: Python, Java, Golang, C/C++\n- Tools: GCP, Vertex AI, Kubernetes, Helm, Docker, git\n- Frameworks/Technologies: LangChain, Mediapipe, TensorFlow, OpenCV, scikit-learn, Redis, MongoDB\n\n2. Education:\n- Master of Science in Computer Science (Thesis) from Virginia Tech, Aug 2024 - Present\n- Bachelor of Technology in Computer Science and Engineering from Manipal University Jaipur, July 2019 - June 2023\n\n3. Work Experience:\n- Software Engineer at Harness [Software Delivery Platform], Bangalore, India\n  - Aug 2023 - July 2024\n  - Software Engineering Intern\n    - Feb 2023 - Aug 2023\n- Research Intern at CVIT Lab - IIIT Hyderabad, Hyd, India\n  - June 2022 – Sept 2022\n\n4. Total Years of Experience: \n- Based on the provided information, Aninditaa Chauhan has approximately 2 years of work experience.\n\nTop 10 Recommended Jobs:\n                                                   title  \\\n22612             1715 - writing an article on economics   \n7294     ML/AI for Orthognathic Surgery Image Processing   \n29887                       Sales and Financial Modeling   \n18511                 Diffusion-generated image detector   \n33497                                   Machine Learning   \n32934                                    AI Image Editor   \n21345               Generative AI Image Generator expert   \n27562  Deep Learning Model for Real-Time Object Detec...   \n31351  Visual Enhancement Specialist for AI-Generated...   \n5911                                         Call center   \n\n                                             description  \\\n22612  1715  - Using social media analysis to improve...   \n7294   I am seeking a highly skilled ML/AI freelancer...   \n29887  Looking for a projection modeling of sales for...   \n18511  Seeking a skilled professional to promptly tes...   \n33497  Role: Machine LearningLocation: RemoteExperien...   \n32934  Description:We are seeking a skilled individua...   \n21345  Hi Upwork folks.We are rebranding our website ...   \n27562  Description:We are seeking an experienced deep...   \n31351  Job DescriptionRole Overview We are on the loo...   \n5911   wanted freshers/ experience day/night ,voice/s...   \n\n                  published_date        country  similarity_score  \n22612  2024-02-20 05:53:38+00:00        Ukraine          0.270398  \n7294   2024-02-19 13:06:17+00:00      Australia          0.246621  \n29887  2024-02-22 19:26:56+00:00  United States          0.245503  \n18511  2024-02-14 03:46:05+00:00  United States          0.244215  \n33497  2024-02-19 12:23:53+00:00          India          0.243700  \n32934  2024-02-22 10:42:37+00:00  United States          0.240904  \n21345  2024-02-23 06:08:09+00:00          India          0.237030  \n27562  2024-02-22 11:30:53+00:00          India          0.235430  \n31351  2024-02-16 23:28:58+00:00    Switzerland          0.231683  \n5911   2024-02-20 13:37:07+00:00          India          0.228170  \n","output_type":"stream"}],"execution_count":105}]}